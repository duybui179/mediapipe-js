<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MediaPipe FaceMesh with 3D Hat Model</title>
  <!-- MediaPipe Scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js" crossorigin="anonymous"></script>
  <!-- Three.js and GLTFLoader Scripts -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r134/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.134/examples/js/loaders/GLTFLoader.js"></script>
  <style>
    body { margin: 0; overflow: hidden; }
    #output_canvas { position: absolute; top: 0; left: 0; }
    #three_canvas { position: absolute; top: 0; left: 0; }
  </style>
</head>
<body>
  <div class="container">
    <video class="input_video" style="display: none;"></video>
    <canvas class="output_canvas" width="1280px" height="720px"></canvas>
    <canvas id="three_canvas" width="1280px" height="720px"></canvas>
  </div>
  <script type="module">
    // MediaPipe Setup
    const videoElement = document.getElementsByClassName('input_video')[0];
    const canvasElement = document.getElementsByClassName('output_canvas')[0];
    const canvasCtx = canvasElement.getContext('2d');

    // Three.js Setup
    const threeCanvas = document.getElementById('three_canvas');
    const scene = new THREE.Scene();
    const camera = new THREE.PerspectiveCamera(45, 1280 / 720, 0.1, 1000);
    camera.position.z = 5;
    const renderer = new THREE.WebGLRenderer({ canvas: threeCanvas, alpha: true });
    renderer.setSize(1280, 720);

    // Add ambient light
    const light = new THREE.AmbientLight(0xffffff);
    scene.add(light);

    // Load the low-poly hat model
    const loader = new THREE.GLTFLoader();
    let hatModel;
    loader.load(
      'assets/low_poly_hat/hat.gltf', // Adjust path and filename as needed
      (gltf) => {
        hatModel = gltf.scene;
        hatModel.scale.set(0.5, 0.5, 0.5); // Adjust scale to fit head
        hatModel.rotation.set(0, 0, 0); // Adjust rotation (e.g., rotate 90 degrees around X-axis)
        scene.add(hatModel);
      },
      (xhr) => console.log((xhr.loaded / xhr.total * 100) + '% loaded'),
      (error) => console.error('Error loading GLTF model:', error)
    );

    // MediaPipe FaceMesh Configuration
    const faceMesh = new FaceMesh({
      locateFile: (file) => {
        return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
      }
    });
    faceMesh.setOptions({
      maxNumFaces: 1,
      refineLandmarks: true,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    // Process FaceMesh results
    faceMesh.onResults((results) => {
      // Clear the 2D canvas
      canvasCtx.save();
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);

      if (results.multiFaceLandmarks) {
        for (const landmarks of results.multiFaceLandmarks) {
          // Draw face mesh (optional, for visualization)
          drawConnectors(canvasCtx, landmarks, FACEMESH_TESSELATION, { color: '#C0C0C070', lineWidth: 1 });

          // Get forehead landmark (e.g., landmark 10)
          const forehead = landmarks[10];
          const x = forehead.x * 1280;
          const y = forehead.y * 720;
          const z = forehead.z * 1000; // Scale z to match Three.js units

          // Map to Three.js coordinate system
          const threeX = (x - 640) / 1280 * 5; // Scale to Three.js units
          const threeY = -(y - 360) / 720 * 5; // Invert y-axis
          const threeZ = -z / 100; // Scale and invert z-axis

          // Position the hat model on the forehead
          if (hatModel) {
            hatModel.position.set(threeX, threeY + 0.25, threeZ); // Offset Y to place hat above forehead
          }
        }
      }
      canvasCtx.restore();

      // Render Three.js scene
      renderer.render(scene, camera);
    });

    // Start the camera
    const cameraFeed = new Camera(videoElement, {
      onFrame: async () => {
        await faceMesh.send({ image: videoElement });
      },
      width: 1280,
      height: 720
    });
    cameraFeed.start();
  </script>
</body>
</html>